---
format: html
editor: visual
mainfont: Times new roman
monofont: Times new roman
include-in-header:
  - text: |
      <style>
      
      html {
        font-size: 12px;
      }
      
      body {
        font-size: 0.75rem;
      }
      
      h3 {
        text-align: left;
      }
      
      .center h2 {
        text-align: center;
      }
      
      .center h3 {
        text-align: center;
        font-size: 1.25rem;
      }
      
      .left h2 {
        text-align: left;
      }
      
      .left h3 {
        text-align: left;
      }
      
      p {
        text-align: justify !important
      }
      
      code{ 
        text-wrap: balance;
      }
      
      </style>
---

```{r}
#| echo: false
options(warn.conflicts = FALSE)

suppressWarnings(library(carData, warn.conflicts = FALSE))
suppressWarnings(library(zoo, warn.conflicts = FALSE))
suppressWarnings(library(readxl, warn.conflicts = FALSE))
suppressWarnings(library(ggplot2, warn.conflicts = FALSE))
suppressWarnings(library(nortest, warn.conflicts = FALSE)) 
suppressWarnings(library(moments, warn.conflicts = FALSE)) 
suppressWarnings(library(car, warn.conflicts = FALSE))
suppressWarnings(library(lmtest, warn.conflicts = FALSE))
suppressWarnings(library(agricolae, warn.conflicts = FALSE)) 
suppressWarnings(library(gplots, warn.conflicts = FALSE)) 

```

```{r}
#| echo: false 
library(lmtest)

alfaNormalidad <- 0.05

pruebaNormalidadShapiro <- function(datos, alfa, h0, ha) { 
  resultado <- shapiro.test(datos) 
  print(resultado)
  if (resultado$p.value > alfa) {
    cat("Dado que el valor-p ", resultado$p.value, " es mayor que el nivel de significancia ", alfa , " no se rechaza H0, y se concluye que ", h0, ".")
  } else {
    cat("Dado que el valor-p ", resultado$p.value, " es menor que el nivel de significancia ", alfa , " se rechaza H0, y se concluye que ", ha, ".")
  }
}

pruebaNormalidadJarque <- function(datos, alfa, h0, ha) { 
  resultado <- jarque.test(datos) 
  print(resultado)
  if (resultado$p.value > alfa) {
    cat("Dado que el valor-p ", resultado$p.value, " es mayor que el nivel de significancia ", alfa , " no se rechaza H0, y se concluye que ", h0, ".")
  } else {
    cat("Dado que el valor-p ", resultado$p.value, " es menor que el nivel de significancia ", alfa , " se rechaza H0, y se concluye que ", ha, ".")
  }
}

pruebaNormalidadLillie <- function(datos, alfa, h0, ha) { 
  resultado <- lillie.test(datos) 
  print(resultado)
  if (resultado$p.value > alfa) {
    cat("Dado que el valor-p ", resultado$p.value, " es mayor que el nivel de significancia ", alfa , " no se rechaza H0, y se concluye que ", h0, ".")
  } else {
    cat("Dado que el valor-p ", resultado$p.value, " es menor que el nivel de significancia ", alfa , " se rechaza H0, y se concluye que ", ha, ".")
  }
}

pruebaNormalidadAD <- function(datos, alfa, h0, ha) { 
  resultado <- ad.test(datos) 
  print(resultado)
  if (resultado$p.value > alfa) {
    cat("Dado que el valor-p ", resultado$p.value, " es mayor que el nivel de significancia ", alfa , " no se rechaza H0, y se concluye que ", h0, ".")
  } else {
    cat("Dado que el valor-p ", resultado$p.value, " es menor que el nivel de significancia ", alfa , " se rechaza H0, y se concluye que ", ha, ".")
  }
}

pruebaIgualdadVarianzasLevene <- function(datos, alfa, h0, ha) { 
  resultado <- leveneTest(datos) 
  print(resultado)
  pvalue<-resultado$'Pr(>F)'[1]
  if ( pvalue > alfa) {
    cat("Dado que el valor-p ", pvalue, " es mayor que el nivel de significancia ", alfa , " no se rechaza H0, y se concluye que ", h0, ".")
  } else {
    cat("Dado que el valor-p ", pvalue, " es menor que el nivel de significancia ", alfa , " se rechaza H0, y se concluye que ", ha, ".")
  }
}

pruebaIgualdadVarianzasLeveneConjunta <- function(grupo, datos, alfa, h0, ha) { 
  resultado <- leveneTest(grupo, data=datos) 
  print(resultado)
  pvalue<-resultado$'Pr(>F)'[1]
  if ( pvalue > alfa) {
    cat("Dado que el valor-p ", pvalue, " es mayor que el nivel de significancia ", alfa , " no se rechaza H0, y se concluye que ", h0, ".")
  } else {
    cat("Dado que el valor-p ", pvalue, " es menor que el nivel de significancia ", alfa , " se rechaza H0, y se concluye que ", ha, ".")
  }
}

pruebaIgualdadVarianzasBartlett <- function(datos, alfa, h0, ha) { 
  resultado <- bartlett.test(datos)
  print(resultado)
  pvalue<-resultado$p.value
  if ( pvalue > alfa) {
    cat("Dado que el valor-p ", pvalue, " es mayor que el nivel de significancia ", alfa , " no se rechaza H0, y se concluye que ", h0, ".")
  } else {
    cat("Dado que el valor-p ", pvalue, " es menor que el nivel de significancia ", alfa , " se rechaza H0, y se concluye que ", ha, ".")
  }
}

pruebaIgualdadVarianzasBreuschPagan <- function(datos, alfa, h0, ha) { 
  resultado <- bptest(datos)
  print(resultado)
  pvalue<-resultado$p.value
  if ( pvalue > alfa) {
    cat("Dado que el valor-p ", pvalue, " es mayor que el nivel de significancia ", alfa , " no se rechaza H0, y se concluye que ", h0, ".")
  } else {
    cat("Dado que el valor-p ", pvalue, " es menor que el nivel de significancia ", alfa , " se rechaza H0, y se concluye que ", ha, ".")
  }
}

pruebaIndependencia <- function(datos, alfa, h0, ha) { 
  resultado <- dwtest(datos)
  print(resultado)
  pvalue<-resultado$p.value 
  if ( pvalue > alfa) {
    cat("Dado que el valor-p ", pvalue, " es mayor que el nivel de significancia ", alfa , " no se rechaza H0, y se concluye que ", h0, ".")
  } else {
    cat("Dado que el valor-p ", pvalue, " es menor que el nivel de significancia ", alfa , " se rechaza H0, y se concluye que ", ha, ".")
  }
  
  print(".")
  
  DW<-resultado$statistic 
  if (DW > 1.5 && DW < 2.5) {
    cat("Dado que el DW ", DW, " es cercano a 2 no se rechaza H0, y se concluye que ", h0, ".")
  } else {
    cat("Dado que el DW ", DW, " no es cercano a 2 no se rechaza H0, y se concluye que ", h0, ".")
  }
}



```

## Diseño factorial {.center}

### Juan Carlos Gaviria Chaverra, Andrés Orlando López Henao {.center}

**1. Plan y ejecución del experimento**

**1.1. Título del experimento**

Influencia de la arquitectura de redes neuronales convolucionales en la exactitud de predicción de señales de tránsito.

**1.2. Objetivos**

Evaluar cómo diferentes arquitecturas de redes neuronales convolucionales afectan la exactitud de predicción de señales de tránsito.

**1.3. Marco teórico**

Se ha observado un incremento significativo en la cantidad de fatalidades ocasionadas por percances automovilísticos a nivel global, siendo la causa primordial la falta de familiaridad con las indicaciones viales y las vías, aunque la razón más común es en parte el desconocimiento de ciertas señales viales específicas (OMS, 2022). Los incidentes de tránsito representan para la mayoría de las naciones un 3% de su producto interno bruto (PIB). Entre los años 2015 y 2030, se estima que estos incidentes tendrán un costo para la economía mundial de 1,8 billones de dólares, lo que equivale al 0,12% del PIB global (Al-Rousan et al., 2021). El aprendizaje automático consiste en un conjunto de técnicas y procedimientos destinados a generar inteligencia artificial mediante el uso de algoritmos y grandes volúmenes de datos con el fin de simular el proceso de aprendizaje (Gu et al., 2108). El aprendizaje profundo, como una subdivisión del aprendizaje automático, se basa en arquitecturas de redes neuronales con múltiples capas internas, tales como las Redes Neuronales Convolucionales (CNN) (Indolia et al., 2018). La identificación de señales de tráfico (TSR por sus siglas en inglés) constituye una tarea de visión artificial y aprendizaje automático que implica el reconocimiento y clasificación de señales de tráfico a partir de imágenes o secuencias de video (Liu et al., 2019). Los algoritmos de visión artificial para la detección de señales de tráfico se relacionan directamente con sus atributos distintivos. Principalmente, las señales de tráfico adoptan formas como triángulos, rectángulos, círculos u octágonos, además de presentar colores (Sheikah et al., 2016). Los colores empleados en las señales de tráfico suelen ser colores básicos como rojo, azul, negro, blanco, amarillo y, de forma menos frecuente, verde. Por ende, los enfoques de detección se clasifican principalmente en métodos basados en color y forma para determinar la característica de la imagen (Fan y Zhang, 2015). En el contexto de la visión por computadora, el reconocimiento de imágenes se refiere a la habilidad del software para identificar elementos, individuos, lugares, escritos y actividades en imágenes. Para llevar a cabo dicha identificación, los sistemas computacionales pueden emplear tecnologías de visión por computadora en combinación con cámaras y software basado en inteligencia artificial. (SearchEnterpriseAI).

**1.4. Variable respuesta**

Para el experimento, la variable respuesta es:

-   ***Variable***: Exactitud de predicción.

-   ***Valores usuales de operación***: Entre 0 y 100.

-   ***Precisión de medición***: Porcentaje.

-   ***Instrumento de medida***: Computador.

**1.5. Variables de control**

A continuación se describen las variables de control del experimento:

Tabla 1. Variables de control

+-----------------+--------------------------------+-------------------------+-------------------------+---------------------------+-----------------------------------------------------------------------------------+
| *Variable*      | *Valores usuales de operación* | *Precisión de medición* | *Instrumento de medida* | *Configuración propuesta* | *Efecto predicho*                                                                 |
+=================+================================+=========================+=========================+===========================+===================================================================================+
| *Convoluciones* | Entre 1 y 10                   | Número entero           | No aplica               | \[1, 2\]                  | La exactitud de predicción aumentará a mayor número de convoluciones.             |
+-----------------+--------------------------------+-------------------------+-------------------------+---------------------------+-----------------------------------------------------------------------------------+
| *Filtros*       | Entre 1 y 100                  | Número entero           | No aplica               | \[4, 16\]                 | La exactitud de predicción aumentará a mayor número de filtros.                   |
+-----------------+--------------------------------+-------------------------+-------------------------+---------------------------+-----------------------------------------------------------------------------------+
| *Densa*         | Entre 1 y 1000                 | Número entero           | No aplica               | \[65, 128\]               | La exactitud de predicción aumentará a mayor número de neuronas en la capa densa. |
+-----------------+--------------------------------+-------------------------+-------------------------+---------------------------+-----------------------------------------------------------------------------------+

**1.6. Factores controlables**

En las tablas 2 y 3 se presentan los factores que se mantendrán constantes durante el experimento:

Tabla 2. Factores externos al modelo CNN

+------------+------------------+---------------------------+-------------------------+------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| *Variable* | *Nivel deseado*  | *Precisión de medición*   | *Instrumento de medida* | *Control*                                                                                                  | *Impacto esperado*                                                                                                                                                                                    |
+============+==================+===========================+=========================+============================================================================================================+=======================================================================================================================================================================================================+
| *Dataset*  | Superior a 70000 | Imágenes de 32x32 píxeles | No aplica               | Se usarán las mismas 58511 imágenes de entrenamiento y 14630 imágenes de validación para todos los modelos | Obtención de una mejor comprensión de cómo diferentes configuraciones afectan el rendimiento del modelo, con el fin de identificar la arquitectura más adecuada para mejorar la exactitud predictiva. |
+------------+------------------+---------------------------+-------------------------+------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

Tabla 3. Factores internos del modelo CNN

+--------------------------+------------------------------------+-------------------------+-------------------------+----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| *Variable*               | *Nivel deseado*                    | *Precisión de medición* | *Instrumento de medida* | *Control*                                                                                                                        | *Impacto esperado*                                                                                                                                                                                                                                                                     |
+==========================+====================================+=========================+=========================+==================================================================================================================================+========================================================================================================================================================================================================================================================================================+
| *Funcion de activación*  | Depende de la función seleccionada | No aplica               | No aplica               | Se aplicará la función de activación RELU para las capas convolucionales y la primera capa densa, y softwax para la última capa. | Obtenención de una consistencia en el comportamiento de los modelos y en una extracción de características más uniforme a lo largo de las capas.                                                                                                                                       |
+--------------------------+------------------------------------+-------------------------+-------------------------+----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| *Compilación del modelo* | No aplica                          | No aplica               | No aplica               | Se usarán los parametros:                                                                                                        | Aseguramiento de la coherencia en el proceso de entrenamiento y evaluación. Esto garantiza que todos los modelos sean entrenados y evaluados de manera similar, facilitando la comparación de sus desempeños y simplificando la gestión de los experimentos de aprendizaje automático. |
|                          |                                    |                         |                         |                                                                                                                                  |                                                                                                                                                                                                                                                                                        |
|                          |                                    |                         |                         | loss='binary_crossentropy'                                                                                                       |                                                                                                                                                                                                                                                                                        |
|                          |                                    |                         |                         |                                                                                                                                  |                                                                                                                                                                                                                                                                                        |
|                          |                                    |                         |                         | optimizer='adam'                                                                                                                 |                                                                                                                                                                                                                                                                                        |
|                          |                                    |                         |                         |                                                                                                                                  |                                                                                                                                                                                                                                                                                        |
|                          |                                    |                         |                         | metrics=\['accuracy'\]                                                                                                           |                                                                                                                                                                                                                                                                                        |
+--------------------------+------------------------------------+-------------------------+-------------------------+----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

**1.7. Factores no controlables**

A continuación se describen en las tablas 4 y 5 los factores que no se mantendrán constantes durante el experimento:

Tabla 4. Factores externos al modelo CNN

+--------------------------------------+-----------------+-------------------------+-------------------------+----------------------------------------------+-----------------------------------------------------------------------------------+
| *Variable*                           | *Nivel deseado* | *Precisión de medición* | *Instrumento de medida* | Estrategia                                   | *Efectos anticipados*                                                             |
+======================================+=================+=========================+=========================+==============================================+===================================================================================+
| *Procesamiento computacional*        | No aplica       | No aplica               | No aplica               | Uso de configuraciones idénticas de hardware | Variación en el tiempo de procesamiento, limitando el número de muestras a tomar. |
+--------------------------------------+-----------------+-------------------------+-------------------------+----------------------------------------------+-----------------------------------------------------------------------------------+
| *Tiempo de entrenamiento por modelo* | Entre 0 y 60    | Minutos                 | Cronómetro              | Uso de configuraciones idénticas de hardware | Limitación en el número de muestras a tomar.                                      |
+--------------------------------------+-----------------+-------------------------+-------------------------+----------------------------------------------+-----------------------------------------------------------------------------------+

Tabla 5. Factores internos modelo CNN

+------------+-----------------+-------------------------+-------------------------+--------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| *Variable* | *Nivel deseado* | *Precisión de medición* | *Instrumento de medida* | *Estrategia*             | Efectos anticipados                                                                                                                                                                                                                                                                                                          |
+============+=================+=========================+=========================+==========================+==============================================================================================================================================================================================================================================================================================================================+
| *Pesos*    | Entre 0 y 1     | Número real             | No aplica               | Inicialización aleatoria | La inicialización aleatoria de pesos en una red neuronal convolucional promueve la diversidad desde el inicio del entrenamiento, ayudando a evitar mínimos locales y aumentando la capacidad del modelo para adaptarse a diferentes conjuntos de datos. Esto mejora la capacidad de generalización y la robustez del modelo. |
+------------+-----------------+-------------------------+-------------------------+--------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

**1.8. Interacciones**

1.  Interacción entre el número de convoluciones y el número de filtros.

2.  Interacción entre el número de convoluciones y el número de neuronas de la capa densa.

3.  Interacción entre el número de filtros y el número de neuronas de la capa densa.

4.  Interacción entre el número de convoluciones, el número de filtros y el número de neuronas de la capa densa.

**1.9. Restricciones**

Debido a los altos requisitos computacionales de los experimentos con redes neuronales convolucionales, fue necesario utilizar el servicio en la nube Google Colab. Tanto en sus versiones gratuitas como de pago, este servicio impone límites en el tiempo de ejecución. Cuando se agota este tiempo, es necesario esperar hasta el día siguiente para continuar. Por lo tanto, la principal limitación fue el tiempo de procesamiento proporcionado por el servicio, considerando un tiempo estimado de 10 minutos para el entrenamiento de cada modelo. Dado que se planeaba realizar pruebas con 8 modelos y realizar 10 ejecuciones de cada uno, se requerían al menos 14 horas de tiempo de computación.

**1.10. Diseño**

Se utilizará un diseño factorial el cual involucra tres factores: el numero de convoluciones, numero de filtros aplicados a cada convolucion y el numero de neuronas de la capa densa con lo cual se logrará medir el reconocimiento de señales de tráficos (TSDR) mediante el uso de una red neuronal convolucional (CNN) para determinar la significancia estadística de los efectos de los factores y sus interacciones para comprender como influyen en conjunto en la esactitud de la prediccion de la red neuronal al reconocer las imagenes de tránsito

**Factores:**

Para el experimento se tomaron los siguientes factores:

-   ***Convoluciones***: Número de convoluciones

-   ***Filtros***: Número de filtros aplicados en cada convolución

-   ***Densa***: Número de neuronas de la capa densa final de la red neuronal

**Tratamientos:**

La nomenclatura usada para identificar cada tratamiento es **Cx_Fy_Dz** donde: *x* representa el número de convoluciones, *y* representa número de filtros y *z* el numero de neuronas de la capa densa. De la combinación de los niveles de los factores, convoluciones, filtros y neuronas de la capa densa surgen los siguientes 8 tratamientos.

Tabla 6. Tratamientos

| Identificador | Convoluciones | Filtros | Neuronas capa densa |
|---------------|---------------|---------|---------------------|
| C1_F4_D64     | 1             | 4       | 64                  |
| C1_F4_D128    | 1             | 4       | 128                 |
| C1_F16_D64    | 1             | 16      | 64                  |
| C1_F16_D128   | 1             | 16      | 128                 |
| C2_F4_D64     | 2             | 4       | 64                  |
| C2_F4_D128    | 2             | 4       | 128                 |
| C2_F16_D64    | 2             | 16      | 64                  |
| C2_F16_D128   | 2             | 16      | 128                 |

**Materiales:**

-   **Entorno de ejecución:** Google colab

-   **Lenguaje de programación:** Python (TensorFlow y Keras)

-   **Conjunto de datos:** <https://www.kaggle.com/datasets/flo2607/traffic-signs-classification>

-   **Herramientas de análisis estadístico:** Lenguaje de programación R

-   **Documentación y registro:** Información de acceso libre

**Procedimiento:**

-   Definición de los factores

-   Determinar los niveles de los factores

-   Diseño del experimento factorial

-   Entrenamiento y evaluación de la CNN

-   Realización del análisis factorial:

-   Optimización y validación

-   Iteración y refinamiento

**Análisis de Datos:** Analizar la exactitud de los modelos para cada una de las configuraciones de la CNN que permitan establecer las interacciones que brinden los mejores porcentajes de predicción de las imágenes de tráfico dentro del diseño de análisis factorial de nivel

**Hipótesis:**

**Hipótesis de efecto principal**: Las convulsiones, filtros y densas no tienen efectos principales significativos sobre la exactitud de la red neuronal convolucional (CNN).

**Hipótesis de interacciones:** Las interacciones entre los diferentes factores no afectan conjuntamente el la exactitud de la red neuronal convolucional (CNN).

**Hipótesis de no linealidad:** Los efectos de los factores son lineales**.**

**Hipótesis de optimización:** No existe una combinación optima de factoresque maximice la exactitud de la red neuronal convolucional.

**Resultados Esperados:**

**Efectos principales:** Se espera que ciertos factores tengan impactos significativos en la exactitud de la red neuronal convolucional**.**

**Interacciones entre factores:** Se espera que se encuentren diferencias significativas entre los factores.

**Tendencias no lineales:** Quelos efectos de ciertos factores no sean lineales.

**Configuraciones optimas:** Quelas configuraciones optimas maximicen la exactitud de la red neuronal convolucional.

**1.11. Descripción**

La técnica de análisis y presentación utilizada en este experimento de 3 factores se basa en una combinación de herramientas estadísticas y gráficas diseñadas para explorar y comunicar los resultados de manera efectiva.

**Gráficas** Se utilizan histogramas para visualizar la distribución de los datos en cada tratamiento, lo que permite una comprensión rápida de la forma y la dispersión de los datos. Los gráficos de cajas para comparar la distribución de los datos entre los diferentes tratamientos, mostrando la mediana, los cuartiles y los valores atípicos y los gráficos de dispersión para explorar la relación entre variables, como los valores ajustados y los residuos.

**ANOVAs:** Se realiza un ANOVA para comparar las medias de los tratamientos y determinar si hay diferencias significativas entre ellos. Se evalúa la significancia estadística, lo que proporciona información sobre la variabilidad entre los tratamientos en relación con la variabilidad dentro de los tratamientos. Después de realizar el ANOVA, se realiza la prueba Tukey como una prueba para comparar todas las combinaciones posibles de pares de tratamientos y determinar qué diferencias son significativas.

**Modelos de Efectos, Medias y Regresión:** Se utilizan diferentes modelos para analizar los datos según la pregunta de investigación. El modelo de efectos considera cada tratamiento como un factor independiente, mientras que el modelo de medias agrupa los tratamientos y compara las medias globales. El modelo de regresión permite explorar la relación entre la variable dependiente y las variables independientes.

**Pruebas de Homocedasticidad y Normalidad:** Se realizan pruebas de homocedasticidad para evaluar si la varianza de los residuos es constante en todos los tratamientos.

Las pruebas de normalidad Anderson-Darling, Shapiro-Wilk, Jarque-Bera, Kolmogorov-Smirnov se utilizarán para verificar si los residuos siguen una distribución normal.

**Valores Ajustados vs Residuales e Independencia de Errores:** Con las pruebas Levene, Bartlett, Breusch-Pagan y Durbin-Watson, Se examina la relación entre los valores ajustados y los residuos para evaluar la idoneidad del modelo. Además, se verifica la independencia de errores para garantizar que los errores no estén correlacionados entre sí

**Comparación entre Tratamientos:** Se realizan comparaciones entre tratamientos utilizando los métodos de la diferencia significativa menos significativa (LSD) y la diferencia significativa honesta (HSD) para identificar las diferencias significativas entre los tratamientos y agruparlos en categorías homogéneas.

En resumen, esta técnica de análisis y presentación utiliza una variedad de herramientas estadísticas y gráficas para explorar y comunicar los resultados de manera efectiva en un experimento de 1 factor con 4 tratamientos. Se enfoca en la comparación de medias, la relación entre variables, la evaluación de la normalidad y homocedasticidad de los residuos, y la identificación de diferencias significativas entre tratamientos.

**1.12. Responsable de coordinación**

Andrés Orlando López Henao.

**1.13. Premuestreo**

Se llevó a cabo un premuestreo con el fin de establecer la configuración óptima del modelo CNN, buscando alcanzar una precisión superior al 70% sin sacrificar un tiempo de entrenamiento excesivo, dada la limitada capacidad de cómputo proporcionada por el servicio de Google Colab y las restricciones temporales del proyecto.

Inicialmente, se diseñaron dos modelos CNN:

1.  Un modelo con 2 capas de convolución, cada una con 4 filtros, y una capa densa con 64 neuronas.
2.  Un modelo con 4 capas de convolución, cada una con 16 filtros, y una capa densa con 128 neuronas.

Ambos modelos fueron entrenados durante 3 épocas para evaluar su desempeño y tiempo de entrenamiento. Posteriormente, se incrementó gradualmente el número de épocas con la intención de alcanzar una precisión superior al 90%. Se encontró que el modelo de 2 convoluciones lograba esta precisión con 10 épocas, con un tiempo de entrenamiento medio entre 1 y 1.5 minutos por época. Sin embargo, el modelo de 4 convoluciones, a pesar de su mayor complejidad, no alcanzaba la precisión deseada en un tiempo aceptable, lo que podría atribuirse a la reducción excesiva de la imagen debido a la aplicación de múltiples convoluciones en imágenes tan pequeñas.

Ante la dificultad de entrenamiento y los límites de capacidad computacional, se evaluó un enfoque más simple con un modelo de 1 convolución, logrando la precisión esperada en menos de 1 minuto de entrenamiento por época, lo que demostró ser más eficiente y efectivo dadas las limitaciones del entorno de cómputo disponible.

**2. Análisis**

**2.1 Datos**

```{r}
#| echo: false

datos <- suppressWarnings(read_excel("datos/datos.xlsx"))
datos$convoluciones <- as.factor(datos$convoluciones)
datos$filtros <- as.factor(datos$filtros)
datos$densa <- as.factor(datos$densa)
head(datos, 50)
```

```{r}
#| echo: false
C1_F4_D64 <-  subset(datos, datos$tratamiento =="C1_F4_D64")
C1_F4_D128 <-  subset(datos, datos$tratamiento =="C1_F4_D128")
C1_F16_D64 <-  subset(datos, datos$tratamiento =="C1_F16_D64")
C1_F16_D128 <-  subset(datos, datos$tratamiento =="C1_F16_D128")
C2_F4_D64 <-  subset(datos, datos$tratamiento =="C2_F4_D64")
C2_F4_D128 <-  subset(datos, datos$tratamiento =="C2_F4_D128")
C2_F16_D64 <-  subset(datos, datos$tratamiento =="C2_F16_D64")
C2_F16_D128 <-  subset(datos, datos$tratamiento =="C2_F16_D128")
```

**2.2. Análisis exploratorio**

```{r}
#| echo: false
 
ggplot(datos,aes(x=tratamiento, y=exactitud, group=tratamiento))+
  geom_boxplot()+
  scale_y_continuous(breaks = seq(0, 20000, by = 1))+
  labs(title = "Gráfico de cajas", x = "Tratamientos", y = "Exactitud") 
```

En este análisis exploratorio de los tratamientos con respecto a la exactitud, podemos observar que posiblemente existan diferencias significativas entre algunos de los tratamientos con respecto al comportamiento del modelo de red neuronal, uno de los que mayor distancia toma con respecto a los otros es el arreglo C2_F16_D128, si se observa se puede ver, que los arreglos C1_F16_D64, C1_F4_D128, C1_F4_D64, están aparentemente distanciado del ya mencionado C2_F16_D128 quien por otro lado parece ser es el de mayor porcentaje de exactitud a la hora de predecir las imágenes de tránsito para corroborar dichas apreciaciones deberemos realizar un análisis de factores de efetos principales que permita establecer los valores de significancia entre los arreglos y la exactitud que brinda el modelo.

```{r}
#| echo: false
 
ggplot(datos,aes(x=convoluciones, y=exactitud, group=tratamiento))+
  geom_boxplot()+
  scale_y_continuous(breaks = seq(0, 20000, by = 1))+
  labs(title = "Gráfico de cajas", x = "Convoluciones", y = "Exactitud") 


```

Para el caso de estas interacciones entre convoluciones y la exactitud de manera exploratoria podemos ver que el numero de 2 convoluciones parece no distanciarse de una manera significativa de aquellos que solo presentan 1 convolución, por lo cual en este caso si es muy pertinente poder realizar un análisis mas detallado en las pruebas de significancia de las interacciones entre factores que nos puedan dar una mayor claridad de la relación entre estas dos características dentro del modelo de red neuronal.

```{r}
#| echo: false
 
ggplot(datos,aes(x=filtros, y=exactitud, group=tratamiento))+
  geom_boxplot()+
  scale_y_continuous(breaks = seq(0, 20000, by = 1))+
  labs(title = "Gráfico de cajas", x = "Filtros", y = "Exactitud") 


```

Entre la exactitud y el factor filtro parece seguir el mismo comportamiento que el factor convolucional ya que no es claro poder observar diferencias directa entre este factor y la exactitud de igual modo debemos apelar al análisis de factores directos que permitan mostrar el valor de la significancia para con estas métricas poder concluir si realmente existen diferencias significativas directas entre este factor y la exactitud.

```{r}
#| echo: false
 
ggplot(datos,aes(x=densa, y=exactitud, group=tratamiento))+
  geom_boxplot()+
  scale_y_continuous(breaks = seq(0, 20000, by = 1))+
  labs(title = "Gráfico de cajas", x = "Capa densa", y = "Exactitud") 


```

Entre la exactitud y capa densa parece nuevamente no haber diferencias ya que todas las cajas están en posiciones muy similares o almenos no se observa que alguna de ellas tome distancias considerables sobre las otras por lo que también es pertinente poder realizar pruebas de significancias que permitan comprobar dicho supuesto ya que de manera exploratoria no es claro que pueda haber diferencias.  

```{r}
#| echo: false
ggplot(datos, aes(x = convoluciones,  y = exactitud, group = convoluciones)) +
  geom_boxplot() + 
  xlab("convoluciones") +
  ylab("exactitud")  
```

Mediante estos gráficos directos de caja entre exactitud y convoluciones es muchísimo mas claro ver que posiblemente no existan diferencias significativas entre la exactitud y la convolución ya que las cajas muestran tener unas formas y traslapes muy similares lo que posiblemente nos haría descartar dicha posibilidad que el p-value este por encima de 0,05.

```{r}
#| echo: false
ggplot(datos, aes(x = filtros,  y = exactitud, group = filtros)) +
  geom_boxplot() + 
  xlab("filtros") +
  ylab("exactitud")  
```

Mediante estos gráficos directos de caja, entre exactitud y filtros de manera exploratoria podemos ver la similitud en la distancia de las cajas con respeto a sus cuartiles, aunque la media pareciera inclinarse para el uso de 16 filtro no pareciera que esa distancia entre medias con respecto a los 4 filtros pueda llegar a presentar diferencia significativa sin embargo es importante poder comprobar este supuesto con la prueba de factores.  

```{r}
#| echo: false
ggplot(datos, aes(x = densa,  y = exactitud, group = densa)) +
  geom_boxplot() + 
  xlab("densa") +
  ylab("exactitud")  
```

A través de la visualización de gráficos de caja comparativos entre la exactitud y la densidad de forma exploratoria, podemos observar similitudes en la distribución de los datos en términos de sus cuartiles. Aunque la media parece favorecer el uso de 128 neuronas en lugar de 64, no parece haber una diferencia significativa entre las medias de ambas configuraciones. No obstante, para validar esta suposición, nuevamente es crucial realizar pruebas de factores.

```{r}
#| echo: false
tapply(datos$exactitud, datos$convoluciones, summary)
tapply(datos$exactitud, datos$filtros, summary)
tapply(datos$exactitud, datos$densa, summary)  
```

```{r}
#| echo: false
# Histograma de exactitud
ggplot(datos, aes(x = exactitud)) +
  geom_histogram(fill = "white", color = "black")  
```

**Gráficos de medias**

```{r}
#| echo: false
#  
require(gplots)
par(mfrow=c(1,3))
plotmeans(datos$exactitud  ~ datos$convoluciones, xlab="convoluciones", ylab="Promedio de exactitud")
plotmeans(datos$exactitud  ~ datos$filtros, xlab="filtros", ylab="Promedio de exactitud")
plotmeans(datos$exactitud  ~ datos$densa, xlab="densa", ylab="Promedio de exactitud")

mean(datos$exactitud)

require(graphics)
plot.design(datos$exactitud ~ datos$convoluciones + datos$filtros  + datos$densa,
            col= "coral", xlab="Efectos", ylab="Promedio de exactitud")

par(mfrow=c(1,3))
interaction.plot(datos$convoluciones, datos$filtros, datos$exactitud, 
                  xlab="convoluciones", ylab="Promedio de exactitud")
interaction.plot(datos$convoluciones, datos$densa, datos$exactitud, 
                 xlab="convoluciones", ylab="Promedio de exactitud")
interaction.plot(datos$filtros, datos$densa,datos$ exactitud, 
                 xlab="filtros", ylab="Promedio de exactitud")
  
```

Interpretaciones

En estos 3 gráfico podemos observar de manera exploratoria como se distribuyen las medias con respecto a cada uno de los factores, pero además las diferencias que existen dentro de los valores de cada factor, en la primera grafica vemos que en el caso de las convoluciones se observa que la media con respecto a 2 capas es superior a la de 1 capa, pero en la gráfica; las pestañas se traslapan, lo que indica que a pesar de ser medias diferentes, posiblemente no existan diferencias entre los valores conjuntos, caso contrario se puede observar en las medias de los filtros y densas; logramos ver que en el primero, la media de 16 filtros  es muy superior a la de 4, además vemos que en el gráfico las pestañas nos se traslapan, lo que en esta gráfica, podría darnos luces de la existencia de diferencias significativas en el uso de mayores filtros en la red neuronal, algo similar observamos en el factor densa, aunque son menores las diferencia entre las medias de 64 y 128 neuronas, también vemos que 128 podría funcionar mejor que 64 con respecto al modelo de exactitud de la red neuronal. 
Ya en el segundo gráfico observamos que entre los tres factores el que mas representan fuerza en la exactitud del modelo son el numero de filtros en segundo lugar el numero de neuronas y por ultimo las convoluciones, pero si miramos en detalle observamos que las diferencias entre los tres factores son muy mínimas situación que permite pensar que posiblemente no existan diferencias entre las interacciones.
Ya en la 3 gráfica es evidente poder considerar que al no haber cruce entre las líneas para ninguno de los factores se podrían considerar la no existencia de diferencias significativa almenos dentro de ellos por lo cual es pertinente poder realizar la prueba entre factores para mirar si posiblemente existen diferencias entre las interacciones.


**2.3. ANOVA**

```{r}
#| echo: false
# Usar datos1: datos codificados como factores
modelo <-  aov(exactitud ~ convoluciones*filtros*densa, data=datos)
summary(modelo)

modelo1 <- aov(exactitud ~ filtros*densa + convoluciones*densa + convoluciones*filtros, data=datos)
summary(modelo1)

residuales <- rstandard(modelo1)

library(car)
qqPlot(residuales)

require(nortest)
shapiro.test(residuales)
ad.test(residuales)  
```

Interpretaciones

Luego de realizar la prueba de normalidad de los datos con una prueba de Shapiro-Wilk: p-value de 0.08737 y otra de Anderson-Darling p-value de 0.06672, además de las pruebas de homocedasticidad Levane con valores de p-value de 0.1032221 además de la prueba de independencia de Durbin-Watson con p-value de xxxxxxx procedemos al confirmar todos los supuestos a realizar el análisis de varianza multifactorial lo cual En esta análisis de varianza multifactorial podemos ver la existencia de diferencias significativas de la variable de respuesta exactitud con respecto a cada uno de los factores, convoluciones, filtros y densa ya que observamos en el p-value de la prueba está por debajo de 0,05 lo que establece y corrobora la existencia de diferencias significativas en cada uno de los factores para cada uno de los factores con respecto a la variable de respuesta exactitud de predicción de la red en el caso de la lectura de las imágenes, caso contrario muestran las interacciones dobles; convoluciones:filtros, convoluciones:densa, filtros:densa, donde encontramos que estas interacciones sus p-value están por encima de 0,05, al igual que las interacciones entre los tres factores convoluciones.filtro:densa por lo cual podemos concluir la no existencia de diferencias significativas entre las interacciones, lo cual podríamos decir que estas no aportan a los porcentajes de exactitud del modelo de red neuronal convolucional (CNN).

```{r}
#| echo: false
# Usar datos2: datos codificados como valores numericos

modelolm <-  lm(exactitud ~ as.numeric(convoluciones)*as.numeric(filtros)*as.numeric(densa), data=datos)
summary(modelolm)

modelolm6 <-  lm(exactitud ~ as.numeric(convoluciones)*as.numeric(filtros)*as.numeric(densa), data=datos)
summary(modelolm6)  
```

Interpretaciones ...

**2.4. Diagrama de Pareto de efectos estandarizados**

```{r}
#| echo: false
# 

efectos <- c(-5.6, -22.3, 31.1, -7.3, -9.6, 47.0, -1.9)
se_efecto <- sqrt(21/4)
efectos_est <- efectos/se_efecto
efectos_est_ord <- sort(abs(efectos/se_efecto))
names(efectos_est_ord) <- c("c_f_d", "c", "c_f", "c_d", "f", "d", "f_d")
#efectos_est_ord  <- relabels()
 
barplot(efectos_est_ord , horiz=TRUE, las=1, 
        col="darkcyan")
abline(v=qt(0.975, 8), col="black", lwd=3, lty =3)  
```

Interpretaciones ...

**Sin la interaccion triple**

```{r}
#| echo: false
# 
modelo1 <-  aov(exactitud ~ convoluciones*filtros + convoluciones*densa + filtros*densa, datos)
summary(modelo1)

modelolm1 <-  lm(exactitud ~ as.numeric(convoluciones)*as.numeric(filtros) +
                  as.numeric(convoluciones)*as.numeric(densa) + 
                  as.numeric(filtros)*as.numeric(densa), data=datos)
summary(modelolm1)
```

**2.5. Identificacion de outlier**

```{r}
#| echo: false
# 
# Esta es una prueba estadistica para identificar puntos outliers
outlierTest(modelolm1)

plot(fitted(modelolm1), residuals(modelolm1))
```

**Eliminacion de outlier**

```{r}
#| echo: false
# 
#datos1 <- datos[-11,]
datos1 <- datos[]

# datos1 <- datos[-c(11, 5),] # 2 outliers en la posici?n 11 y 5

datos1$convoluciones <- as.factor(datos1$convoluciones)
datos1$filtros <- as.factor(datos1$filtros)
datos1$densa <- as.factor(datos1$densa)

modelo2 <-  aov(datos1$exactitud ~ datos1$convoluciones*datos1$filtros + 
                  datos1$convoluciones*datos1$densa + datos1$filtros*datos1$densa)
summary(modelo2)

modelo2 <- aov(exactitud ~ convoluciones*filtros + convoluciones*densa + filtros*densa, datos1)
summary(modelo2)

modelolm2 <-  lm(datos1$exactitud ~ as.numeric(datos1$convoluciones)*as.numeric(datos1$filtros) +
                  as.numeric(datos1$convoluciones)*as.numeric(datos1$densa) + 
                  as.numeric(datos1$filtros)*as.numeric(datos1$densa))
summary(modelolm2)
```

**2.6. Análisis de residuales**

```{r}
#| echo: false
#---------------- ----------------
residuales <- rstandard(modelo2)
summary(residuales)
```

**Prueba de normalidad**

```{r}
#| echo: false
# 
require(car)
par(mfrow=c(1,3))
qqPlot(residuales, xlab="Cuantiles teoricos", ylab="Cuantiles muestrales", main="Gr?fico cuantil-cuantil")
hist(residuales, xlab="Residuales", ylab="Frecuencia", main="Histograma")
boxplot(residuales, xlab="Residuales",  main="Gr?fico de cajas")
```

```{r}
#| echo: false 
#| 
h0 <- "los residuales siguen una distribución normal"
ha <- "los residuales no siguen una distribución normal"

cat("H0: ", h0) 
cat("HA: ", ha)

```

**Prueba de normalidad Anderson-Darling**

```{r}
#| echo: false 
#| 
pruebaNormalidadAD(residuales, alfaNormalidad, h0, ha) 

```

**Prueba de normalidad Shapiro-Wilk**

```{r}
#| echo: false 
#| 
pruebaNormalidadShapiro(residuales, alfaNormalidad, h0, ha) 

```

**Prueba de varianza constante**

```{r}
#| echo: false
# 
valores_ajustados<-fitted(modelo2)

par(mfrow=c(2,2))
plot(valores_ajustados, residuales, xlab="Valores ajustados", ylab="Residuales")
abline(h=0, col = "gray60")
plot(as.numeric(datos1$convoluciones), residuales, xlab="convoluciones", ylab="Residuales")
abline(h=0, col = "gray60")
plot(as.numeric(datos1$filtros), residuales, xlab="filtros", ylab="Residuales")
abline(h=0, col = "gray60")
plot(as.numeric(datos1$densa), residuales, xlab="densa", ylab="Residuales")
abline(h=0, col = "gray60")
```

interpretaciones...

```{r}
#| echo: false 

alfaVarianzas<-0.05
h0 <- "Las varianzas de la precisión son iguales en todos los niveles de la variable convoluciones"
ha <- "Las varianzas de la precisión no son iguales en todos los niveles de la variable convoluciones"

cat("H0: ", h0) 
cat("HA: ", ha)

```

**Prueba de iguadad de varianzas Levene**

```{r}
#| echo: false    
pruebaIgualdadVarianzasLeveneConjunta(exactitud ~ convoluciones, datos1, alfaVarianzas, h0, ha)
```

```{r}
#| echo: false 

alfaVarianzas<-0.05
h0 <- "Las varianzas de la precisión son iguales en todos los niveles de la variable filtros"
ha <- "Las varianzas de la precisión no son iguales en todos los niveles de la variable filtros"

cat("H0: ", h0) 
cat("HA: ", ha)

```

**Prueba de iguadad de varianzas Levene**

```{r}
#| echo: false    
pruebaIgualdadVarianzasLeveneConjunta(exactitud ~ filtros, datos1, alfaVarianzas, h0, ha)
```

```{r}
#| echo: false 

alfaVarianzas<-0.05
h0 <- "Las varianzas de la precisión son iguales en todos los niveles de la variable densa"
ha <- "Las varianzas de la precisión no son iguales en todos los niveles de la variable densa"

cat("H0: ", h0) 
cat("HA: ", ha)

```

```{r}
#| echo: false    
pruebaIgualdadVarianzasLeveneConjunta(exactitud ~ densa, datos1, alfaVarianzas, h0, ha)
```

```{r}
#| echo: false 

alfaVarianzas<-0.05
h0 <- "Las varianzas de la precisión son iguales en todos los niveles de la variable convoluciones y filtros, y sus interacciones"
ha <- "Las varianzas de la precisión no son iguales en todos los niveles de la variable convoluciones y filtros, y sus interacciones"

cat("H0: ", h0) 
cat("HA: ", ha)

```

```{r}
#| echo: false    
pruebaIgualdadVarianzasLeveneConjunta(exactitud ~ convoluciones*filtros, datos1, alfaVarianzas, h0, ha)
```

```{r}
#| echo: false 

alfaVarianzas<-0.05
h0 <- "Las varianzas de la precisión son iguales en todos los niveles de la variable convoluciones y densa, y sus interacciones"
ha <- "Las varianzas de la precisión no son iguales en todos los niveles de la variable convoluciones y densa, y sus interacciones"

cat("H0: ", h0) 
cat("HA: ", ha)

```

```{r}
#| echo: false    
pruebaIgualdadVarianzasLeveneConjunta(exactitud ~ convoluciones*densa, datos1, alfaVarianzas, h0, ha)
```

```{r}
#| echo: false 

alfaVarianzas<-0.05
h0 <- "Las varianzas de la precisión son iguales en todos los niveles de la variable densa y filtros, y sus interacciones"
ha <- "Las varianzas de la precisión no son iguales en todos los niveles de la variable densa y filtros, y sus interacciones"

cat("H0: ", h0) 
cat("HA: ", ha)

```

```{r}
#| echo: false    
pruebaIgualdadVarianzasLeveneConjunta(exactitud ~ densa*filtros, datos1, alfaVarianzas, h0, ha)
```

**Prueba de independencia**

```{r}
#| echo: false
# 
par(mfrow=c(1,3))
plot(residuales, pch=16, ylab="Residuales", xlab="Orden", main="Gráfico de Orden vs Residuales")
abline(h=0)
acf(residuales,ylim=c(-1,1), main="Grafico de ACF")
pacf(residuales,ylim=c(-1,1), main="Grafico de PACF", ylab="PACF")
```

-   En el gráfico de dispersión de los residuos en función de su orden dentro del conjunto de datos, no se observa un patrón claro en la distribución de los residuos a lo largo del orden. La mayoría de los residuos parecen estar dispersos aleatoriamente alrededor de la línea horizontal en y = 0, lo que sugiere que no hay un patrón sistemático en la relación entre el orden de los datos y los residuos.

**Pruebas estadísticas**

```{r}
#| echo: false   

alfaVarianzas<-0.05
h0 <- "no hay autocorrelación en los residuos."
ha <- "hay autocorrelación en los residuos."

cat("H0: ", h0) 
cat("HA: ", ha)
```

**Prueba Durbin-Watson**

```{r}
#| echo: false   
pruebaIndependencia(modelo2, alfaVarianzas, h0, ha)
```

**2.7. Gráfico de superficie de respuesta**

```{r}
#| echo: false
# #----------------  Eemplo de 
# Ecuaci?n modelo de regresi?n (7)
# a= convoluciones, b= filtros, c=densa 
# ygorro = 60.2958 - 3.7583*a - 10.2417*b + 14.6167*c -4.5958*a*b -3.8792*a*c + 22.5792*b*c
# ygorro = 60.2958 - 3.7583*x - 10.2417*y + 14.6167*(-1) -4.5958*x*y -3.8792*x*(-1) + 22.5792*y*(-1)
# ygorro = 60.2958 - 3.7583*x - 10.2417*y - 14.6167 -4.5958*x*y +3.8792*x - 22.5792*y
# ygorro = (60.2958- 14.6167) - (3.7583*-3.8792)*x - (10.2417+ 22.5792)*y  -4.5958*x*y  
# ygorro = 45.6791 + 0.1209*x -32.8209*y -4.5958*x*y

par(mfrow=c(1,2))
# Superficie de respuesta para c=-1
x     <-  seq(1, 2, 1) # x=convoluciones
y     <-  seq(4, 16, 1) # y=filtros
model <-  function (x, y){45.6791 +0.1209*x -32.8209*y -4.5958*x*y}
z     <-  outer(x, y ,model)

persp(x,y,z, phi=30, theta=130, xlab="convoluciones", ylab="filtros", 
      zlab="Exactitud", col = "lightblue", 
      expand=0.9, ticktype = "detailed")
contour(x,y,z,nlevels=30)
```

Interpretaciones ...

```{r}
#| echo: false
par(mfrow=c(1,2))
# Superficie de respuesta para c=1
x     <-  seq(1, 2, 1) 
y     <-  seq(4, 16, 1)
model <-  function (x, y){74.9125 - 7.6375*x +12.3375*y -4.5958*x*y}
z     <-  outer(x, y ,model)
persp(x,y,z, phi=30, theta=20, xlab="convoluciones", ylab="filtros", 
      zlab="Exactitud", col = "lightblue", 
      expand=0.9, ticktype = "detailed")
contour(x,y,z,nlevels=30)
```

Interpretaciones ...

```{r}
#| echo: false
par(mfrow=c(1,2))
# Superficie de respuesta para b=-1
x     <-  seq(1, 2, 1) 
y     <-  seq(64, 128, 1)
model <-  function (x, y){70.5375 + 0.8375*x -7.9625*y -3.8792*x*y }
z     <-  outer(x, y ,model)
persp(x,y,z, phi=30, theta=120, xlab="convoluciones", ylab="densa", 
      zlab="Exactitud", col = "lightblue", 
      expand=0.9, ticktype = "detailed")
contour(x,y,z,nlevels=30)
```

Interpretaciones ...

```{r}
#| echo: false
par(mfrow=c(1,2))
# Superficie de respuesta para b=1
x     <-  seq(1, 2, 1) 
y     <-  seq(64, 128, 1)
model <-  function (x, y){50.0541 -8.3541*x + 37.1959*y -3.8792*x*y }
z     <-  outer(x, y ,model)
persp(x,y,z, phi=30, theta=120, xlab="convoluciones", ylab="densa", 
      zlab="Exactitud", col = "lightblue", 
      expand=0.9, ticktype = "detailed")
contour(x,y,z,nlevels=30)
```

Interpretaciones ...

```{r}
#| echo: false
par(mfrow=c(1,2))
# Superficie de respuesta para a=-1
x     <-  seq(4, 16, 1) 
y     <-  seq(64, 128, 1)
model <-  function (x, y){64.0541-5.6459*x + 18.4959*y + 22.5792*x*y}
z     <-  outer(x, y ,model)
persp(x,y,z, phi=30, theta=30, xlab="filtros", ylab="densa", 
      zlab="Exactitud", col = "lightblue", 
      expand=0.9, ticktype = "detailed")
contour(x,y,z,nlevels=30)
```

Interpretaciones ...

```{r}
#| echo: false
par(mfrow=c(1,2))
# Superficie de respuesta para a=1 
x     <-  seq(4, 16, 1) 
y     <-  seq(64, 128, 1)
model <-  function (x, y){ 56.5375 - 14.8375*x + 10.7375*y + 22.5792*x*y}
z     <-  outer(x, y ,model)
persp(x,y,z, phi=30, theta=20, xlab="filtros", ylab="densa", 
      zlab="Exactitud", col = "lightblue", 
      expand=0.9, ticktype = "detailed")
contour(x,y,z,nlevels=30)
```

Interpretaciones ...

**Grafico con plotly**

```{r}
#| echo: false
# 
library(plotly)
fig <- plot_ly(x=x, y=y, z=z)
fig <- fig %>% add_surface()
fig
```

Interpretaciones ...

```{r}
#| echo: false
#
library(plotly)
fig <- plot_ly(x=x, y=y, z=z) %>% add_surface(
  contours = list(
    z = list(
      show=TRUE,
      usecolormap=TRUE,
      highlightcolor="#ff0000",
      project=list(z=TRUE)
    )
  )
)
fig <- fig %>% layout(
  scene = list(
    camera=list(
      eye = list(x=1.87, y=0.88, z=-0.64)
    )
  )
)

fig
```

Interpretaciones ...

**2.8. Comparaciones múltiples**

```{r}
#| echo: false
# Comparaciones múltiples
require(agricolae)
#LSD.test(modelo2, "densa", console=TRUE, group=FALSE)
#plot(LSD.test(modelo2, "convoluciones", group = FALSE,console = T))

#TukeyHSD(modelo2, "convoluciones",ordered = T)
```

Interpretaciones ...

```{r}
#| echo: false
#Tamaño de muestra = Número de réplicas

# Cálculo de potencia para replicas predeterminadas
# Considerando el tamaño del efecto
# D es la mínima diferencia entre los niveles del factor A
# sigma^2 es la vaianza de todos los datos 
# f.a <- sqrt((a*D^2)/(2*b*sigma^2))

# D es la mínima diferencia entre los niveles del factor B
# sigma^2 es la vaianza de todos los datos 
# f.b <- sqrt((b*D^2)/(2*a*sigma^2))

require(pwr2)
# Factor A convoluciones y Factor B filtros
f.a <- sqrt((2*0.4^2)/(2*2*var(datos$exactitud)))
f.b <- sqrt((2*12.5^2)/(2*2*var(datos$exactitud)))
P1 <- pwr.2way(a=2, b=2, alpha = 0.05, size.A = 3, size.B = 3, f.A = f.a, f.B = f.b)

require(pwr2)
# Factor A convoluciones y Factor B densa
f.a <- sqrt((2*0.4^2)/(2*2*var(datos$exactitud)))
f.b <- sqrt((2*5.3^2)/(2*2*var(datos$exactitud)))
P2 <- pwr.2way(a=2, b=2, alpha = 0.05, size.A = 3, size.B = 3, f.A = f.a, f.B = f.b)

require(pwr2)
# Factor A convoluciones y Factor B filtros
f.a <- sqrt((2*12.5^2)/(2*2*var(datos$exactitud)))
f.b <- sqrt((2*5.3^2)/(2*2*var(datos$exactitud)))
P3 <- tres <- pwr.2way(a=2, b=2, alpha = 0.05, size.A = 3, size.B = 3, f.A = f.a, f.B = f.b)

potencia <- min(cbind(P1$power, P2$power, P3$power))
potencia
```

Interpretaciones ...

**2.9. Cálculo de réplicas**

```{r}
#| echo: false
# Cálculo de réplicas para alpha y beta definidos
# Factor A convoluciones y Factor B filtros
f.a <- sqrt((2*0.4^2)/(2*2*var(datos$exactitud)))
f.b <- sqrt((2*12.5^2)/(2*2*var(datos$exactitud)))
n1 <- ss.2way(a=2, b=2, alpha = 0.1, beta = 0.1, f.A = f.a, f.B = f.b, B=100)

# Factor A convoluciones y Factor B densa
f.a <- sqrt((2*0.4^2)/(2*2*var(datos$exactitud)))
f.b <- sqrt((2*5.3^2)/(2*2*var(datos$exactitud)))
n2 <- ss.2way(a=2, b=2, alpha = 0.1, beta = 0.1, f.A = f.a, f.B = f.b, B=100)

# Factor A convoluciones y Factor B filtros
f.a <- sqrt((2*12.5^2)/(2*2*var(datos$exactitud)))
f.b <- sqrt((2*5.3^2)/(2*2*var(datos$exactitud)))
n3 <- ss.2way(a=2, b=2, alpha = 0.1, beta = 0.1, f.A = f.a, f.B = f.b, B=100)

replicas <- min(cbind(n1$n, n2$n, n3$n))
replicas
```

Interpretaciones ...

# Referencias

Al-Rousan, Taleb M. y Abdullahi A. Umar. Evaluación de los niveles de comprensión de las señales de tráfico entre los conductores en el Emirato de Abu Dhabi, Emiratos Árabes Unidos. Infraestructuras 6, núm. 9 (2021): 122. https://doi.org/10.3390/infrastructures6090122.

Fan, Y., Zhang, W. Detección y clasificación de señales de tráfico para sistemas avanzados de asistencia al conductor. En la 12.ª Conferencia Internacional sobre Sistemas Difusos y Descubrimiento de Conocimiento (FSKD), 2015, págs. 1335-1339.

Gu J., Wang Z., Kuen J., Ma L., Shahroudy A., Shuai B., Liu T., Wang X., Wang L., Wang G., Cai J., Chen T. Avances recientes en redes neuronales convolucionales. Reconocimiento de patrones, 2018, N 77, págs. 354-377. https://doi.org/10.1016/J.PATCOG.2017.10.013.

Indolia S., Goswami AK, Mishra SP, Asopa P. Comprensión conceptual de la red neuronal convolucional: un enfoque de aprendizaje profundo. Procedia Informática, 2018, N 132, págs. 679 -- 688. https://doi.org/10.1016/J.PROCS.2018.05.069

Liu, S. Li, F. Chang e Y. Wang, "Métodos de detección de señales de tráfico basados en visión artificial: revisión, análisis y perspectivas", en IEEE Access, vol. 7, págs. 86578-86596, 2019, https://doi.org/10.1109/ACCESS.2019.2924947.

Organización mundial de la salud (OMS) 2022. Lesiones por accidentes de tráfico, "Organización Mundial de la Salud (OMS)", \[en línea\], https://www.who.int/newsroom/factsheets/detail/road-lesiones de trafico.

Sheikh, AA, Kole, A., Maity, T. Detección y clasificación de señales de tráfico mediante funciones de color y redes neuronales. En Conferencia Internacional sobre Instrumentación y Energía de Control Inteligente (ICICPI), 2016, págs. 307-311.

Reconocimiento de imágenes, SearchEnterpriseAI \[en línea\] Disponible: https://www.techtarget.com/searchenterpriseai/definition/imagerecognition \[Consultado el 19 de abril de 2024\].
